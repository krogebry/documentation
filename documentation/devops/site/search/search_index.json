{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Index page","text":"<p>DevOps documentation page.</p>"},{"location":"aws/","title":"AWS specific things","text":"<pre><code>aws sts get-caller-identity\n</code></pre>"},{"location":"aws/#ecr-login","title":"ECR Login","text":"<pre><code>aws ecr get-login-password | docker login --username AWS --password-stdin AWS_ACCOUNT_ID.dkr.ecr.us-east-1.amazonaws.com\n</code></pre>"},{"location":"aws/#alias","title":"Alias","text":"<pre><code>alias ecr_login=\"aws ecr get-login-password | docker login --username AWS --password-stdin AWS_ACCOUNT_ID.dkr.ecr.us-east-1.amazonaws.com\"\n</code></pre>"},{"location":"aws/#find-latest-ami","title":"Find latest AMI","text":"<pre><code>aws ec2 describe-images --owners 1234 --filters \"Name=name,Values=ubuntu-20.04-20230208221620\"  </code></pre>"},{"location":"aws/#add-up-the-ebs-volumes-that-are-unattached","title":"Add up the EBS volumes that are unattached.","text":"<pre><code>aws ec2 describe-volumes --filters \"Name=status,Values=available\" | jq '[.Volumes[].Size|tonumber]|add'\n</code></pre>"},{"location":"aws/#get-unattached-eips","title":"Get unattached EIPs","text":"<pre><code>aws ec2 describe-addresses --query 'Addresses[?AssociationId==null]'|jq '.[].AllocationId'\n</code></pre>"},{"location":"aws/#cleanup-eips","title":"Cleanup EIPs","text":"<pre><code>for eip in $(aws ec2 \\\ndescribe-addresses \\\n--query 'Addresses[?AssociationId==null]'|jq -r '.[].AllocationId'); do aws ec2 release-address --allocation-id ${eip}; done\n</code></pre>"},{"location":"aws/#get-latest","title":"Get latest","text":"<p>Reference</p> <pre><code>aws ssm \\\nget-parameter \\\n--region us-east-1 \\\n--query \"Parameter.Value\" \\\n--output text \\\n--name /aws/service/eks/optimized-ami/1.27/amazon-linux-2/recommended/image_id\n</code></pre> <p>Result: <code>ami-013895b64fa9cbcba</code></p>"},{"location":"aws/ssm/","title":"SSM","text":"<p>Reference</p> <p>Create a port forward to :3306 on a remote service via an SSM tunnel.</p> <pre><code>aws ssm \\\nstart-session \\\n--target &lt;ssm-managed-instance-id&gt; \\\n--document-name AWS-StartPortForwardingSessionToRemoteHost \\\n--parameters '{\"portNumber\":[\"3306\"],\"localPortNumber\":[\"1053\"],\"host\":[\" remote-database-host-name\"]}'\n</code></pre>"},{"location":"github/","title":"Overview","text":"<p>Using workflows as bundles of actions.</p>"},{"location":"github/#actions","title":"Actions","text":"<p>A collection of reusable code bits to make things easier.</p> <p>Github Actions</p>"},{"location":"github/#workflows","title":"Workflows","text":"<p>Collection of shared workflows that call actions</p> <p>Workflows</p>"},{"location":"helm/","title":"Helm","text":"<p>I prefer helm to other approaches.</p> <p>Using starters</p> <p>@TODO:</p> <ul> <li>Library versus starters</li> <li>Problems using library charts</li> <li>Expansive values files</li> <li>\"Programming\" a single master chart versus using single charts</li> </ul> <p>Enforcing standards.</p>"},{"location":"helm/libraries/","title":"Overview","text":"<p>Splitting things out for specific use cases.</p>"},{"location":"helm/testing/","title":"Overview","text":"<p>Using <code>go</code> to test helm charts.</p> <pre><code>graph LR\n  A[Start] --&gt; B[Lint];\n  B --&gt; Deploy[Deploy to K8s];\n  Deploy --&gt; Test[Test];\n  Test --&gt; GoTest[go test];\n  Test --&gt; KubeScore[kube-score];\n  Test --&gt; SecurityScan[wiz scan];\n  GoTest --&gt; Publish[Publish to art];\n  KubeScore --&gt; Publish;\n  SecurityScan --&gt; Publish;</code></pre>"},{"location":"kubernetes/","title":"Overview","text":"<p>Handy things to know about k8s.</p>"},{"location":"kubernetes/#delete-old-jobs","title":"Delete old jobs","text":"<pre><code>kubectl get \\\njobs -A -o json|jq -r \\\n'.items[]|select(.status.failed == 1)|\\\"kubectl delete job -n \\\" + .metadata.namespace + \\\" \\\" + .metadata.name '\"\n</code></pre>"},{"location":"kubernetes/#exec-into-a-devops-utility-pod","title":"Exec into a devops utility pod","text":"<pre><code>alias du=\"kubectl exec -ti \\$(kubectl get pods -lapp.kubernetes.io/instance=devops-utility-box -o json|jq -r '.items[0].metadata.name') -- /bin/bash\"\n</code></pre>"},{"location":"kubernetes/aws-eks/","title":"Update kubeconfig","text":"<pre><code>aws eks update-kube-config\n</code></pre>"},{"location":"kubernetes/opa/","title":"Open Policy Agent","text":"<p>Highly secure k8s.</p>"},{"location":"terraform/","title":"Organization","text":"<p>My Terraform</p>"},{"location":"terraform/#aliases","title":"Aliases","text":"<pre><code>alias t=\"/usr/local/bin/terraform\"\n</code></pre> <p>@TODO: <code>tfenv</code></p>"},{"location":"terraform/#modules","title":"Modules","text":"<p>Use versioned modules.</p>"},{"location":"terraform/security/","title":"Security","text":"<p>This document explains how to best organize terraform resources such that we optimize around:</p> <ul> <li>Creating environments that are resistant to change.</li> <li>Allow developers to impact changes in the most secure way keeping them safe from accidental changes.</li> <li>Limit the blast radius of a security compromise or developer mistake by providing a \"least permission\" model around the automation system.</li> </ul>"},{"location":"terraform/security/#organization","title":"Organization","text":"<p>In general, I tend to organize my terraform in the following structure:</p> LayoutExample <ul> <li>repo_name:<ul> <li>terraform/</li> <li>provider/ <ul> <li>region or zone/<ul> <li>env_name/<ul> <li>infra/</li> <li>bootstrap/</li> <li>application/</li> </ul> </li> </ul> </li> </ul> </li> </ul> </li> </ul> <ul> <li>my_awesome_project.git:<ul> <li>terraform/<ul> <li>aws<ul> <li>us-east-1<ul> <li>dev<ul> <li>infra</li> <li>bootstrap</li> <li>application</li> </ul> </li> <li>stage<ul> <li>infra</li> <li>bootstrap</li> <li>application</li> </ul> </li> <li>production<ul> <li>infra</li> <li>bootstrap</li> <li>application</li> </ul> </li> <li>ap-northeast-1</li> <li>dev<ul> <li>infra</li> <li>bootstrap</li> <li>application</li> </ul> </li> <li>stage<ul> <li>infra</li> <li>bootstrap</li> <li>application</li> </ul> </li> <li>production<ul> <li>infra</li> <li>bootstrap</li> <li>application</li> </ul> </li> </ul> </li> <li>observability<ul> <li>wavefront<ul> <li>infra</li> <li>dev</li> <li>stage</li> <li>production</li> </ul> </li> <li>pager-duty</li> </ul> </li> </ul> </li> </ul> </li> </ul> </li> </ul>"},{"location":"terraform/security/#blast-radius","title":"Blast radius","text":"<p>This layout allows us to ensure a few critical things in our infrasutructure design:</p> <ul> <li>Administrators own both the <code>infra</code> and <code>bootstrap</code> directories. <ul> <li>Things in <code>bootstrap</code> are only used once.</li> <li>Things in infra change infrequently and are run by hand ( not CI/CD ).</li> </ul> </li> <li>Application developers can PR infrastructure changes via changes to the anything in the <code>application</code> directory</li> <li>The CI/CD workflows are configured to run off of any changes in <code>application</code>.</li> <li>The most important aspect of this is that we're NOT requiring an admin user for CI/CD </li> </ul> <p>Using an admin user to automatically run <code>infra</code> or <code>application</code> ( or both ) would expose our automation  to a high-level, potentially large surface area of compromise if the admin user was every actually  compromised for whatever reason.</p> <p>Instead, I usually aim at exposing the automation to <code>least perm</code> or \"Least possible permissions\" in order to help lower the overall surface area of potential exposure in the automation system.</p>"},{"location":"terraform/security/#example","title":"Example","text":"<p>In this example we'll use a very simple AWS roll out.  In this case the <code>bootstrap</code> would be setup for us already. Which means the s3 bucket for state and DynamoDB table for state locking are already setup.</p> <p>I would start by running <code>terraform apply</code> in the <code>infra</code> repo, which will setup an IAM user with a trust relationship for our github org/repo/env.  This IAM role has the absolute minimum IAM permissions for the next part, which is the <code>application</code> deployment.</p> <p>Next, we would expect our Github ( or whatever ) workflow to kick off and execute several steps:</p> <ul> <li>Start by executing the OIDC workflow to assume the IAM role setup by the <code>infra</code> terraform.</li> <li>Once the role is assumed, we can now execute <code>terraform plan/apply</code></li> </ul>"},{"location":"terraform/security/#diagram","title":"Diagram","text":"<pre><code>flowchart TD\n    Infra[Deploy Infra] --&gt; AWSInfra[Create IAM Roles for App];\n    AWSInfra --&gt; AWS;\n    AWSApp -.-&gt; AWSInfra;\n    Application[Deploy Application] --&gt; AWSApp[Use IAM Role];\n    AWSApp --&gt; AWS;</code></pre>"},{"location":"terraform/vault/","title":"Vault","text":"<p>Setting up vault on a managed service.</p>"},{"location":"tips-and-tricks/","title":"Tips and Tricks","text":"<p>Stuff </p>"},{"location":"tips-and-tricks/aws/","title":"AWS","text":"<p>Specific tips and tricks.</p>"},{"location":"tips-and-tricks/helm/","title":"Helm repo and https","text":"<p>This URL:</p> <pre><code>https://artifactory.mycooldomain.com/artifactory\n</code></pre> <p>Is different from this URL:</p> <pre><code>https://artifactory.mycooldomain.com:433/artifactory\n</code></pre> <p>Here's the deal, with the <code>:443</code> URL you can authenticate and even scrape the index.  However, you cannot pull down an archive fromt he repo.</p> <p>Apparently the <code>:443</code> has some weird impact on downloads of archives.  The result will be a 401 when trying to  install a chart.</p> <p>However, you won't get the same 401 when updating or authenticating to the repository.</p> <p>Weird, right?  This was not a fun thing to discover.</p>"},{"location":"tips-and-tricks/jq/","title":"JQuery","text":"<p>Tips and tricks using <code>jq</code></p>"},{"location":"tips-and-tricks/k8s/","title":"Overview","text":"<p>Various things that have helped me manage k8s environments.</p> <p>Warning</p> <p>Please use kubie!!</p>"},{"location":"tips-and-tricks/k8s/#bash-shortcuts","title":"Bash shortcuts","text":"<p>Thanks to Stefan Gloutnikov for this little gem:</p> <pre><code># Impersonate -admin in Kubie namespace\nkubieKubectlAsAdmin() {\nKUBENS=$(cat $KUBIE_KUBECONFIG | yq '.contexts[0].context.namespace')\nkubectl $(echo \"$@\") --as $KUBENS-admin\n}\nalias ka='kubieKubectlAsAdmin'\n</code></pre> <p>Put this into your <code>~/.zshrc</code> or <code>~/.bashrc</code> and use as such:</p> <pre><code>ka port-forward svc/service-name 8080:8080\n</code></pre> <p><code>port-forward</code> requires admin permissions, so <code>ka</code> will do that for you as a one-off from your normal commands.</p> <p>You can also use this for various other commands like secrets:</p> <pre><code>ka get secrets\n</code></pre>"},{"location":"tips-and-tricks/k8s/#helm","title":"Helm","text":"<p>In the case of a helm deployment, you might have to use something slightly different:</p> <pre><code># Impersonate -admin in Kubie namespace\nkubieHelmAsAdmin() {\nKUBENS=$(cat $KUBIE_KUBECONFIG | yq '.contexts[0].context.namespace')\nhelm --as-kube-user $KUBENS-admin $(echo \"$@\") }\nalias ha='kubieHelmAsAdmin'\n</code></pre> <p>And use like this to list helm charts:</p> <pre><code>ha list </code></pre>"},{"location":"tips-and-tricks/k8s/#events","title":"Events","text":"<p>Another handy trick is to use something you'll see me use quite often:</p> <pre><code>alias kge='kubectl get events --sort-by='\\''{.lastTimestamp}'\\'''\n</code></pre> <p>This will sort events from the event log, giving you the most recent first.</p>"},{"location":"tips-and-tricks/k8s/#autocomplete","title":"Autocomplete","text":"<p>This snippet enables <code>kubectl</code> autocomplete ( tab out ) and an alias for <code>k</code> <pre><code>source &lt;(kubectl completion zsh)\nalias k=kubectl\ncomplete -F __start_kubectl k\n</code></pre></p> <p>It might not seem like much, but this shortens <code>kubectl</code> to <code>k</code>, and if you're doing a lot of kubectl commands, this can end up being a huge time saver.</p>"}]}